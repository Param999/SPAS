shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
shiny::runApp('C:/Users/varun/Desktop/Major Project/R Studio/Dummy Project')
install.packages("rpart")
install.packages("randomForest")
install.packages("RWeka")
DNA <- read.csv("splice_data.txt", header=T)
head(DNA)
library(datasets)
names(infert)
library(neuralnet)
nn <- neuralnet(
case~age+parity+induced+spontaneous,
data=infert, hidden=2, err.fct="ce",
linear.output=FALSE)
# basic
nn
# reults options
names(nn)
# result matrix
nn$result.matrix
out <- cbind(nn$covariate,nn$net.result[[1]])
dimnames(out) <- list(NULL, c("age", "parity","induced","spontaneous","nn-output"))
head(out)
head(nn$generalized.weights[[1]])
plot(nn)
library(datasets)
names(infert)
library(neuralnet)
nn <- neuralnet(
case~age+parity+induced+spontaneous,
data=infert, hidden=2, err.fct="ce",
linear.output=FALSE)
# basic
nn
# reults options
names(nn)
# result matrix
nn$result.matrix
out <- cbind(nn$covariate,nn$net.result[[1]])
dimnames(out) <- list(NULL, c("age", "parity","induced","spontaneous","nn-output"))
head(out)
head(nn$generalized.weights[[1]])
plot(nn)
library(datasets)
names(infert)
library(neuralnet)
head(names)
nn <- neuralnet(
case~age+parity+induced+spontaneous,
data=infert, hidden=2, err.fct="ce",
linear.output=FALSE)
# basic
nn
# reults options
names(nn)
# result matrix
nn$result.matrix
out <- cbind(nn$covariate,nn$net.result[[1]])
dimnames(out) <- list(NULL, c("age", "parity","induced","spontaneous","nn-output"))
head(out)
head(nn$generalized.weights[[1]])
plot(nn)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
predict(Model, newdata=new.cars)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
predict(cars, newdata=new.cars)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
head(new.cars)
predict(cars, newdata=new.cars)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
head(new.cars)
predict(new.cars, newdata=new.cars)
new.cars <- data.frame(wt=c(1.7, 2.4, 3.6))
head(new.cars)
predict(new.cars, newdata=new.cars, interval='confidence')
require(graphics)
## Predictions
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
## Prediction intervals, special cases
##  The first three of these throw warnings
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
predict(fit, interval = "prediction")
predict(wfit, interval = "prediction")
predict(wfit, new, interval = "prediction")
predict(wfit, new, interval = "prediction", weights = (new$x)^2)
predict(wfit, new, interval = "prediction", weights = ~x^2)
##-- From  aov(.) example ---- predict(.. terms)
npk.aov <- aov(yield ~ block + N*P*K, npk)
(termL <- attr(terms(npk.aov), "term.labels"))
(pt <- predict(npk.aov, type = "terms"))
pt. <- predict(npk.aov, type = "terms", terms = termL[1:4])
stopifnot(all.equal(pt[,1:4], pt.,
tolerance = 1e-12, check.attributes = FALSE))
require(graphics)
## Predictions
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
## Prediction intervals, special cases
##  The first three of these throw warnings
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
predict(fit, interval = "prediction")
predict(wfit, interval = "prediction")
predict(wfit, new, interval = "prediction")
predict(wfit, new, interval = "prediction", weights = (new$x)^2)
predict(wfit, new, interval = "prediction", weights = ~x^2)
##-- From  aov(.) example ---- predict(.. terms)
npk.aov <- aov(yield ~ block + N*P*K, npk)
(termL <- attr(terms(npk.aov), "term.labels"))
(pt <- predict(npk.aov, type = "terms"))
pt. <- predict(npk.aov, type = "terms", terms = termL[1:4])
stopifnot(all.equal(pt[,1:4], pt.,
tolerance = 1e-12, check.attributes = FALSE))
require(graphics)
## Predictions
x <- rnorm(15)
y <- x + rnorm(15)
#predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
#predict(lm(y ~ x), new, se.fit = TRUE)
#pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
#pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
#matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
#lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
## Prediction intervals, special cases
##  The first three of these throw warnings
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
#predict(fit, interval = "prediction")
#predict(wfit, interval = "prediction")
#predict(wfit, new, interval = "prediction")
#predict(wfit, new, interval = "prediction", weights = (new$x)^2)
predict(wfit, new, interval = "prediction", weights = ~x^2)
##-- From  aov(.) example ---- predict(.. terms)
#npk.aov <- aov(yield ~ block + N*P*K, npk)
#(termL <- attr(terms(npk.aov), "term.labels"))
#(pt <- predict(npk.aov, type = "terms"))
#pt. <- predict(npk.aov, type = "terms", terms = termL[1:4])
#stopifnot(all.equal(pt[,1:4], pt.,
#                   tolerance = 1e-12, check.attributes = FALSE))
require(graphics)
x <- rnorm(15)
y <- x + rnorm(15)
new <- data.frame(x = seq(-3, 3, 0.5))
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
predict(wfit, new, interval = "prediction", weights = ~x^2)
require(graphics)
x <- rnorm(15)
y <- x + rnorm(15)
new <- data.frame(x = seq(-3, 3, 0.5))
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
predict(wfit, new, interval = "prediction", weights = ~x^2)
require(graphics)
## Predictions
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
## Prediction intervals, special cases
##  The first three of these throw warnings
w <- 1 + x^2
fit <- lm(y ~ x)
wfit <- lm(y ~ x, weights = w)
predict(fit, interval = "prediction")
predict(wfit, interval = "prediction")
predict(wfit, new, interval = "prediction")
predict(wfit, new, interval = "prediction", weights = (new$x)^2)
predict(wfit, new, interval = "prediction", weights = ~x^2)
##-- From  aov(.) example ---- predict(.. terms)
npk.aov <- aov(yield ~ block + N*P*K, npk)
(termL <- attr(terms(npk.aov), "term.labels"))
(pt <- predict(npk.aov, type = "terms"))
pt. <- predict(npk.aov, type = "terms", terms = termL[1:4])
stopifnot(all.equal(pt[,1:4], pt.,
tolerance = 1e-12, check.attributes = FALSE))
library("MASS")
> data(cats)
> str(cats)
'data.frame':   144 obs. of  3 variables:
$ Sex: Factor w/ 2 levels "F","M": 1 1 1 1 1 1 1 1 1 1 ...
$ Bwt: num  2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ...
$ Hwt: num  7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ...
> summary(cats)
library("MASS")
data(cats)
str(cats)
summary(cats)
# Set random seed. Don't remove this line.
set.seed(1)
# Chop up iris in my_iris and species
my_iris <- iris[-5]
species <- iris$Species
# Perform k-means clustering on my_iris: kmeans_iris
kmeans_iris <- kmeans(my_iris,3)
# Compare the actual Species to the clustering using table()
table(species, kmeans_iris$cluster)
# Plot Petal.Width against Petal.Length, coloring by cluster
plot(Petal.Length ~ Petal.Width, data = my_iris, col = kmeans_iris$cluster)
# Set random seed. Don't remove this line.
set.seed(1)
# Chop up iris in my_iris and species
my_iris <- iris[-5]
species <- iris$Species
# Perform k-means clustering on my_iris: kmeans_iris
kmeans_iris <- kmeans(my_iris,3)
# Compare the actual Species to the clustering using table()
table(species, kmeans_iris$cluster)
# Plot Petal.Width against Petal.Length, coloring by cluster
plot(Petal.Length ~ Petal.Width, data = my_iris, col = kmeans_iris$cluster)
# Set random seed. Don't remove this line.
set.seed(1)
# Take a look at the iris dataset
str(iris)
summary(iris)
# A decision tree model has been built for you
tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
# A dataframe containing unseen observations
unseen <- data.frame(Sepal.Length = c(5.3, 7.2),
Sepal.Width = c(2.9, 3.9),
Petal.Length = c(1.7, 5.4),
Petal.Width = c(0.8, 2.3))
# Predict the label of the unseen observations. Print out the result.
predict(tree,unseen,type = "class")
library(rattle)
library(rpart.plot)
library(RColorBrewer)
# Set random seed. Don't remove this line.
set.seed(1)
# Take a look at the iris dataset
str(iris)
summary(iris)
# A decision tree model has been built for you
tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
# A dataframe containing unseen observations
unseen <- data.frame(Sepal.Length = c(5.3, 7.2),
Sepal.Width = c(2.9, 3.9),
Petal.Length = c(1.7, 5.4),
Petal.Width = c(0.8, 2.3))
# Predict the label of the unseen observations. Print out the result.
predict(tree,unseen,type = "class")
library(rattle)
library(rpart.plot)
library(RColorBrewer)
# Set random seed. Don't remove this line.
set.seed(1)
# Take a look at the iris dataset
str(iris)
summary(iris)
# A decision tree model has been built for you
tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = iris, method = "class")
# A dataframe containing unseen observations
unseen <- data.frame(Sepal.Length = c(5.3, 7.2),
Sepal.Width = c(2.9, 3.9),
Petal.Length = c(1.7, 5.4),
Petal.Width = c(0.8, 2.3))
# Predict the label of the unseen observations. Print out the result.
predict(tree,unseen,type = "class")
library(gdata)
library(stringr)
setwd("C:/xampp/htdocs/SPAS/pages/RScripts")
dummy <- read.xls("Book3.xls")
dummy <- data.frame(lapply(dummy, as.character), stringsAsFactors=FALSE)
totalDays <- ncol(dummy)
totalDays <- totalDays-6
totalDays
totalStds <- nrow(dummy)
totalStds
stdAct <- data.frame()
stdActX <- data.frame()
kx = 1;
stdActDF <- data.frame()
DF = 1;
stdActVLR <- data.frame()
VLR = 1;
stdActRLR <- data.frame()
RLR = 1;
#stdActAll <- data.frame()
#all = 1;
sumDF = 0;
sumVLR = 0;
sumRLR = 0;
i = 1
j = 7
k = 1;
sink("rAllStdAllActs.txt")
while(i != totalStds+1) {
while(j != totalDays+7) {
var <- dummy[i,j]
l = 1;
a = 3
b = gregexpr(pattern =',',var)
b = as.vector(b[[1]])
count = length(b)
c = b[l] - 2
l = l + 1
while(TRUE) {
var2 <- substr(var,start=a,stop=c)
var2 <- str_split_fixed(var2, ";", 4)
if(var2 == '') {
break;
}
else {
if(var2[2] == "D") {
sumDF = sumDF + as.numeric(var2[4])
}
else if(var2[2] == "R") {
sumRLR = sumRLR + as.numeric(var2[4])
}
else if(var2[2] == "V") {
sumVLR = sumVLR + as.numeric(var2[4])
}
stdAct[k,1] <- var2[1]
stdAct[k,2] <- var2[2]
stdAct[k,3] <- var2[3]
stdAct[k,4] <- var2[4]
#stdActX[kx,1] <- var2[1]
#stdActX[kx,2] <- var2[2]
#stdActX[kx,3] <- var2[3]
#stdActX[kx,4] <- var2[4]
#kx = kx + 1;
a = c + 5
if(count == 1) {
c = nchar(var) - 1
}
else {
c = b[l] - 2
l = l + 1
count = count - 1;
}
cat(stdAct[k,1],sep=" ")
cat(stdAct[k,2],sep=" ")
cat(stdAct[k,3],sep=" ")
cat(stdAct[k,4],sep=" ")
k = k+1
cat("\n")
}
}
if(j != totalDays+6) {
#For New Day
# X For New Day & Y For New Student
stdAct[k,1] <- "X"
stdAct[k,2] <- "X"
stdAct[k,3] <- "X"
stdAct[k,4] <- "X"
cat(stdAct[k,1],sep=" ")
cat(stdAct[k,2],sep=" ")
cat(stdAct[k,3],sep=" ")
cat(stdAct[k,4],sep=" ")
cat("\n")
k = k+1
#New Day
}
j = j + 1
}
#For New Student
# X For New Day & Y For New Student
stdAct[k,1] <- "Y"
stdAct[k,2] <- "Y"
stdAct[k,3] <- "Y"
stdAct[k,4] <- "Y"
#New Student
j = 7
i = i + 1
cat(stdAct[k,1],sep=" ")
cat(stdAct[k,2],sep=" ")
cat(stdAct[k,3],sep=" ")
cat(stdAct[k,4],sep=" ")
#cat("\t")
cat("\n")
k = k+1
stdActDF[DF,1] = sumDF
DF = DF + 1
stdActVLR[VLR,1] = sumVLR
VLR = VLR + 1
stdActRLR[RLR,1] = sumRLR
RLR = RLR + 1
stdActX[kx,1] = sumDF + sumVLR + sumRLR;
kx = kx + 1;
sumDF = 0;
sumVLR = 0;
sumRLR = 0;
}
sink()
sink("rAllStdDFActs.txt")
i = 1;
while(i != DF) {
cat(stdActDF[i,1])
cat("\n")
i = i + 1;
}
i = 1;
sink()
sink("rAllStdRLRActs.txt")
i = 1;
while(i != RLR) {
cat(stdActRLR[i,1])
cat("\n")
i = i + 1;
}
sink()
sink("rAllStdVLRActs.txt")
i = 1;
while(i != VLR) {
cat(stdActVLR[i,1])
cat("\n")
i = i + 1;
}
sink()
var <- kmeans(stdActDF,3)
var
sink("DF_Clusters.txt")
i = 1;
while(!(is.na(var$cluster[i]))) {
cat(var$cluster[i])
cat("\n");
i = i + 1;
}
cat(var$centers[1])
cat("\n");
cat(var$centers[2])
cat("\n");
cat(var$centers[3])
sink()
var <- kmeans(stdActRLR,3)
sink("RLR_Clusters.txt")
i = 1;
while(!(is.na(var$cluster[i]))) {
cat(var$cluster[i])
cat("\n");
i = i + 1;
}
cat(var$centers[1])
cat("\n");
cat(var$centers[2])
cat("\n");
cat(var$centers[3])
sink()
var <- kmeans(stdActVLR,3)
sink("VLR_Clusters.txt")
i = 1;
while(!(is.na(var$cluster[i]))) {
cat(var$cluster[i])
cat("\n");
i = i + 1;
}
cat(var$centers[1])
cat("\n");
cat(var$centers[2])
cat("\n");
cat(var$centers[3])
sink()
stdActX$V1
sink("rAllActs.txt")
i = 1;
while(i <= totalStds) {
cat(stdActX$V1[i])
cat("\n")
i = i + 1;
}
sink()
var <- kmeans(stdActX,3)
sink("ALL_Clusters.txt")
i = 1;
while(!(is.na(var$cluster[i]))) {
cat(var$cluster[i])
cat("\n");
i = i + 1;
}
cat(var$centers[1])
cat("\n");
cat(var$centers[2])
cat("\n");
cat(var$centers[3])
sink()
